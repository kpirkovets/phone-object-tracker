<!-- <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Real-Time Object Tracking</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.18.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <style>
    body { margin: 0; display: flex; flex-direction: column; align-items: center; background: #111; color: white; }
    video, canvas { width: 100%; max-width: 480px; border-radius: 12px; }
    #status { margin: 10px; font-size: 1rem; }
  </style>
</head>
<body>
  <h2>ðŸ“· Real-Time Object Tracking</h2>
  <p id="status">Loading model...</p>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const statusText = document.getElementById('status');

    async function initCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
        video.srcObject = stream;
        return new Promise(resolve => {
          video.onloadedmetadata = () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            resolve();
          };
        });
      } catch (err) {
        alert('Camera access denied or unavailable.');
      }
    }

    async function main() {
      await initCamera();
      statusText.textContent = "Loading object detection model...";
      const model = await cocoSsd.load();
      statusText.textContent = "Model loaded. Detecting objects...";
      
      async function detectFrame() {
        const predictions = await model.detect(video);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        
        predictions.forEach(pred => {
          ctx.beginPath();
          ctx.rect(...pred.bbox);
          ctx.lineWidth = 2;
          ctx.strokeStyle = "#00FF00";
          ctx.fillStyle = "#00FF00";
          ctx.stroke();
          ctx.fillText(`${pred.class} (${Math.round(pred.score*100)}%)`, pred.bbox[0], pred.bbox[1] > 10 ? pred.bbox[1] - 5 : 10);
        });

        requestAnimationFrame(detectFrame);
      }
      
      detectFrame();
    }

    main();
  </script>
</body>
</html> -->


<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Duck Tracker (Fast)</title>
  <style>
    body { margin: 0; background: #111; color: #fff; font-family: sans-serif; text-align: center; }
    video, canvas { width: 100%; max-width: 480px; border-radius: 12px; margin: 10px 0; }
  </style>
</head>
<body>
  <h2>ðŸ¦† Bright Duck Tracker</h2>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>
  <p id="coords">Coordinates: â€“</p>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const coordsText = document.getElementById("coords");

    async function initCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
      video.srcObject = stream;
      return new Promise(resolve => {
        video.onloadedmetadata = () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          resolve();
        };
      });
    }

    function inRange(h, s, v, lower, upper) {
      return (
        h >= lower[0] && h <= upper[0] &&
        s >= lower[1] && s <= upper[1] &&
        v >= lower[2] && v <= upper[2]
      );
    }

    function rgbToHsv(r, g, b) {
      r /= 255; g /= 255; b /= 255;
      const max = Math.max(r, g, b), min = Math.min(r, g, b);
      let h, s, v = max;
      const d = max - min;
      s = max === 0 ? 0 : d / max;
      if (max === min) {
        h = 0;
      } else {
        switch (max) {
          case r: h = ((g - b) / d + (g < b ? 6 : 0)); break;
          case g: h = ((b - r) / d + 2); break;
          case b: h = ((r - g) / d + 4); break;
        }
        h /= 6;
      }
      return [h * 180, s * 255, v * 255]; // H:0â€“180, S:0â€“255, V:0â€“255
    }

    function processFrame() {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const frame = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const data = frame.data;

      let sumX = 0, sumY = 0, count = 0;

      for (let i = 0; i < data.length; i += 4 * 4) { // skip some pixels for speed
        const r = data[i], g = data[i+1], b = data[i+2];
        const [h, s, v] = rgbToHsv(r, g, b);

        // Bright green
        const isGreen = inRange(h, s, v, [35, 100, 100], [85, 255, 255]);
        // Bright orange
        const isOrange = inRange(h, s, v, [5, 150, 150], [25, 255, 255]);

        if (isGreen || isOrange) {
          const pixelIndex = i / 4;
          const x = pixelIndex % canvas.width;
          const y = Math.floor(pixelIndex / canvas.width);
          sumX += x;
          sumY += y;
          count++;
        }
      }

      if (count > 200) { // only show if enough pixels detected
        const cx = sumX / count;
        const cy = sumY / count;
        ctx.beginPath();
        ctx.arc(cx, cy, 20, 0, 2 * Math.PI);
        ctx.lineWidth = 3;
        ctx.strokeStyle = "#00FF00";
        ctx.stroke();
        coordsText.textContent = `Coordinates: (${cx.toFixed(0)}, ${cy.toFixed(0)})`;
      } else {
        coordsText.textContent = "Coordinates: â€“";
      }

      requestAnimationFrame(processFrame);
    }

    (async () => {
      await initCamera();
      processFrame();
    })();
  </script>
</body>
</html>
